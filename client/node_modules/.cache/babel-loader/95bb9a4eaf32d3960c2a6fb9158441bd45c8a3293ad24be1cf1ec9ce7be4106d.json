{"ast":null,"code":"import { Emitter } from \"../util/Emitter\";\nexport class BaseContext extends Emitter {\n  constructor() {\n    super(...arguments);\n    this.isOffline = false;\n  }\n  /*\n   * This is a placeholder so that JSON.stringify does not throw an error\n   * This matches what JSON.stringify(audioContext) returns on a native\n   * audioContext instance.\n   */\n  toJSON() {\n    return {};\n  }\n}","map":{"version":3,"names":["Emitter","BaseContext","constructor","isOffline","toJSON"],"sources":["/Users/ianstrom/Development/code/Capstone/client/node_modules/tone/Tone/core/context/BaseContext.ts"],"sourcesContent":["import { Seconds } from \"../type/Units\";\nimport { Emitter } from \"../util/Emitter\";\nimport { AnyAudioContext } from \"./AudioContext\";\n\ntype Draw = import(\"../util/Draw\").Draw;\ntype Destination = import(\"./Destination\").Destination;\ntype Transport = import(\"../clock/Transport\").Transport;\ntype Listener = import(\"./Listener\").Listener;\n\n// these are either not used in Tone.js or deprecated and not implemented.\nexport type ExcludedFromBaseAudioContext =\n\t| \"onstatechange\"\n\t| \"addEventListener\"\n\t| \"removeEventListener\"\n\t| \"listener\"\n\t| \"dispatchEvent\"\n\t| \"audioWorklet\"\n\t| \"destination\"\n\t| \"createScriptProcessor\";\n\n// the subset of the BaseAudioContext which Tone.Context implements.\nexport type BaseAudioContextSubset = Omit<\nBaseAudioContext,\nExcludedFromBaseAudioContext\n>;\n\nexport type ContextLatencyHint = AudioContextLatencyCategory;\n\nexport abstract class BaseContext\n\textends Emitter<\"statechange\" | \"tick\">\n\timplements BaseAudioContextSubset {\n\t//---------------------------\n\t// BASE AUDIO CONTEXT METHODS\n\t//---------------------------\n\tabstract createAnalyser(): AnalyserNode;\n\n\tabstract createOscillator(): OscillatorNode;\n\n\tabstract createBufferSource(): AudioBufferSourceNode;\n\n\tabstract createBiquadFilter(): BiquadFilterNode;\n\n\tabstract createBuffer(\n\t\t_numberOfChannels: number,\n\t\t_length: number,\n\t\t_sampleRate: number\n\t): AudioBuffer;\n\n\tabstract createChannelMerger(\n\t\t_numberOfInputs?: number | undefined\n\t): ChannelMergerNode;\n\n\tabstract createChannelSplitter(\n\t\t_numberOfOutputs?: number | undefined\n\t): ChannelSplitterNode;\n\n\tabstract createConstantSource(): ConstantSourceNode;\n\n\tabstract createConvolver(): ConvolverNode;\n\n\tabstract createDelay(_maxDelayTime?: number | undefined): DelayNode;\n\n\tabstract createDynamicsCompressor(): DynamicsCompressorNode;\n\n\tabstract createGain(): GainNode;\n\n\tabstract createIIRFilter(\n\t\t_feedForward: number[] | Float32Array,\n\t\t_feedback: number[] | Float32Array\n\t): IIRFilterNode;\n\n\tabstract createPanner(): PannerNode;\n\n\tabstract createPeriodicWave(\n\t\t_real: number[] | Float32Array,\n\t\t_imag: number[] | Float32Array,\n\t\t_constraints?: PeriodicWaveConstraints | undefined\n\t): PeriodicWave;\n\n\tabstract createStereoPanner(): StereoPannerNode;\n\n\tabstract createWaveShaper(): WaveShaperNode;\n\n\tabstract createMediaStreamSource(\n\t\t_stream: MediaStream\n\t): MediaStreamAudioSourceNode;\n\n\tabstract createMediaElementSource(\n\t\t_element: HTMLMediaElement\n\t): MediaElementAudioSourceNode;\n\n\tabstract createMediaStreamDestination(): MediaStreamAudioDestinationNode;\n\n\tabstract decodeAudioData(_audioData: ArrayBuffer): Promise<AudioBuffer>;\n\n\t//---------------------------\n\t// TONE AUDIO CONTEXT METHODS\n\t//---------------------------\n\n\tabstract createAudioWorkletNode(\n\t\t_name: string,\n\t\t_options?: Partial<AudioWorkletNodeOptions>\n\t): AudioWorkletNode;\n\n\tabstract get rawContext(): AnyAudioContext;\n\n\tabstract async addAudioWorkletModule(\n\t\t_url: string,\n\t\t_name: string\n\t): Promise<void>;\n\n\tabstract lookAhead: number;\n\n\tabstract latencyHint: ContextLatencyHint | Seconds;\n\n\tabstract resume(): Promise<void>;\n\n\tabstract setTimeout(\n\t\t_fn: (...args: any[]) => void,\n\t\t_timeout: Seconds\n\t): number;\n\n\tabstract clearTimeout(_id: number): this;\n\n\tabstract setInterval(\n\t\t_fn: (...args: any[]) => void,\n\t\t_interval: Seconds\n\t): number;\n\n\tabstract clearInterval(_id: number): this;\n\n\tabstract getConstant(_val: number): AudioBufferSourceNode;\n\n\tabstract get currentTime(): Seconds;\n\n\tabstract get state(): AudioContextState;\n\n\tabstract get sampleRate(): number;\n\n\tabstract get listener(): Listener;\n\n\tabstract get transport(): Transport;\n\n\tabstract get draw(): Draw;\n\n\tabstract get destination(): Destination;\n\n\tabstract now(): Seconds;\n\n\tabstract immediate(): Seconds;\n\n\t/*\n\t * This is a placeholder so that JSON.stringify does not throw an error\n\t * This matches what JSON.stringify(audioContext) returns on a native\n\t * audioContext instance.\n\t */\n\ttoJSON(): Record<string, any> {\n\t\treturn {};\n\t}\n\n\treadonly isOffline: boolean = false;\n}\n"],"mappings":"AACA,SAASA,OAAO,QAAQ,iBAAiB;AA2BzC,OAAM,MAAgBC,WACrB,SAAQD,OAA+B;EADxCE,YAAA;;IAoIU,KAAAC,SAAS,GAAY,KAAK;EACpC;EAVC;;;;;EAKAC,MAAMA,CAAA;IACL,OAAO,EAAE;EACV"},"metadata":{},"sourceType":"module","externalDependencies":[]}